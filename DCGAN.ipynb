{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review on GAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN is a network combining the generator network $G$ and the discriminator network $D$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to produce $G$ so that the distribution of real samples is similar to the fake ones, but there is a discriminator which can judge between the real and fake ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.legacy.nn as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: $\\hspace{20pt}$ cifar10 / lsun / imagenet / folder / lfw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataroot: $\\hspace{18pt}$ path to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workers: $\\hspace{18pt}$ number of data loading workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$nz$: $\\hspace{37pt}$ size of the latent noisy $z$ vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngf: $\\hspace{34pt}$ number of generator feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndf: $\\hspace{34pt}$ number of discriminator feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--manualSeed'], dest='manualSeed', nargs=None, const=None, default=None, type=<type 'int'>, choices=None, help='manual seed', metavar=None)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw ')\n",
    "parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manualSeed = random.randint(1, 10000)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_show(img, num_img):\n",
    "    fig = plt.figure(figsize=(8,12))\n",
    "    for i in range(num_img):\n",
    "        a=fig.add_subplot(1, num_img , i+1)\n",
    "        image = to_pil(img[i].data)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_show_2(img, num_img):\n",
    "    fig = plt.figure(figsize=(10,14))\n",
    "    for i in range(num_img):\n",
    "        a=fig.add_subplot(1, num_img, i+1)\n",
    "        image = to_pil(img[i])\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights initialization on Generators net $G$ and net $D$. <br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator network G definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of the generator $z$ with dim $nz$ is a noise vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the generator is passed through sequence of deconvolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discriminator network D definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch of fake images is passed through sequence of convolutional layers to give out a probability. <br\\>\n",
    "It is a binary classification problem. So the probability of the sample coming from real ones is given by $y = \\frac{1}{1+\\exp{x}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netD = _netD(ngpu)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary cross entropy is the standard loss criterion to maximum the likelihood of collect labeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, $u=-\\frac{1}{n}\\sum_i [(1-\\delta_i)\\log(1-y_i)+(\\delta_i)\\log(y_i)]$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\delta_i$ is the indicator function of the image $I_i$ being truly the real one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create (i) input $x$ of the image size, and (ii) a noise vector $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(opt.batchSize, 3, opt.imageSize, opt.imageSize)\n",
    "noise = torch.FloatTensor(opt.batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "label = torch.FloatTensor(opt.batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the Adam optimizer with the above defined hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the input image $x$ to the $D$ network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the expectation of  $ - \\log(D(x)) $ in the real sample: $\\mathbb{E}_{P_r}[- \\log(D(x))]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D_x = -\\frac{1}{n}\\sum_{i=1}^{n} [\\log(D(x^{i})) ],$$where $n$ is the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the noise vector $z$ to the $G$ network to give a fake image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fake image will be converted to a probability after passing through $D$ network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the expectation of  $ - \\log(1 - D(G(z)))$ in the fake sample: $$\\mathbb{E}_{P_g}[- \\log(1-D(G(z)))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Error(D_{fake}) = -\\frac{1}{n}\\sum_{i=1}^{n} [ \\log(1 - D(G(z^{i})))],$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss of discriminator is given by $$Error(D) = D_x+Error(D_{fake})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then backward propagation takes place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the generator $G$ is trained to maximize the probability of D making a mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the fake image $g_z$ to the discriminator $D$ and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the expectation of  $ - \\log(D(g_z))$ in the fake sample: $$\\mathbb{E}_{P_r}[- \\log(1-D(g_z))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Error(G) = -\\frac{1}{n}\\sum_{i=1}^{n} [  \\log(D(g_z^{i}))],$$\n",
    "Then backward propagation takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(opt.niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, _ = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "        if opt.cuda:\n",
    "            real_cpu = real_cpu.cuda()\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = netD(inputv)\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, labelv)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oringinal Collection of Input Images \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have two images $I_1,I_2$ of length 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote $I_i^{j}$ the j-th channel of the image $I_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=Variable(torch.floor(torch.rand(2, 3, 4, 4)*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAADcCAYAAAALBWnAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA362+cYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105295250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_show(img, img.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oringinal Collection of Filter Images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now we have three filters $w_1, w_2, w_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denote $w_i^{j}$ the j-th channel of the filter $w_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image shown has zero padding before deconvolution, hence the actual size is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAC5CAYAAABOQsmyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOgAAgAH4P/I1sgLhPo/UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1050d5650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upsample = nn.ConvTranspose2d(3, 3, 3, stride=2, padding=1)\n",
    "filters = upsample.weight.data.normal_(0.0, 0.02) \n",
    "img_show_2(filters,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\tilde{*}$ be the deconvolution operator, and $g$ be the output. Then $$g_{i}^{j} = \\sum_{t} I_{i}^{t} \\hspace{3pt} \\tilde{*} \\hspace{3pt} w_{t}^{j}$$\n",
    "Link: https://i.stack.imgur.com/YyCu2.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAELCAYAAACVh4HXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBBlDAAAoKD/BzeNEfDmAVYqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105cedc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "up_img = upsample(img)\n",
    "img_show_2(up_img.data,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
